x-hadoop: &hadoop_env
  YARN_CONF_yarn_app_mapreduce_am_env: "HADOOP_HOME=/opt/hadoop-3.2.1,HADOOP_MAPRED_HOME=/opt/hadoop-3.2.1"
  MAPRED_CONF_mapreduce_map_env: "HADOOP_HOME=/opt/hadoop-3.2.1,HADOOP_MAPRED_HOME=/opt/hadoop-3.2.1"
  MAPRED_CONF_mapreduce_reduce_env: "HADOOP_HOME=/opt/hadoop-3.2.1,HADOOP_MAPRED_HOME=/opt/hadoop-3.2.1"
  MAPRED_CONF_mapreduce_application__classpath: "/opt/hadoop-3.2.1/etc/hadoop:/opt/hadoop-3.2.1/share/hadoop/common/*:/opt/hadoop-3.2.1/share/hadoop/common/lib/*:/opt/hadoop-3.2.1/share/hadoop/hdfs/*:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/*:/opt/hadoop-3.2.1/share/hadoop/mapreduce/*:/opt/hadoop-3.2.1/share/hadoop/mapreduce/lib/*:/opt/hadoop-3.2.1/share/hadoop/yarn/*:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/*"
  YARN_CONF_yarn_application__classpath: "/opt/hadoop-3.2.1/etc/hadoop:/opt/hadoop-3.2.1/share/hadoop/common/*:/opt/hadoop-3.2.1/share/hadoop/common/lib/*:/opt/hadoop-3.2.1/share/hadoop/hdfs/*:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/*:/opt/hadoop-3.2.1/share/hadoop/mapreduce/*:/opt/hadoop-3.2.1/share/hadoop/mapreduce/lib/*:/opt/hadoop-3.2.1/share/hadoop/yarn/*:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/*"
  YARN_CONF_mapreduce_application__classpath: "/opt/hadoop-3.2.1/etc/hadoop:/opt/hadoop-3.2.1/share/hadoop/common/*:/opt/hadoop-3.2.1/share/hadoop/common/lib/*:/opt/hadoop-3.2.1/share/hadoop/hdfs/*:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/*:/opt/hadoop-3.2.1/share/hadoop/mapreduce/*:/opt/hadoop-3.2.1/share/hadoop/mapreduce/lib/*:/opt/hadoop-3.2.1/share/hadoop/yarn/*:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/*"
  YARN_CONF_yarn_nodemanager_aux___services: "mapreduce_shuffle"
  YARN_CONF_yarn_nodemanager_aux___services_mapreduce__shuffle__class: "org.apache.hadoop.mapred.ShuffleHandler"


services:
  # ---------- S3 Compatible ----------
  minio:
    image: minio/minio:latest
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
    ports:
      - "9000:9000"  # S3 API
      - "9001:9001"  # Consola web
    volumes:
      - minio_data:/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 10s
      timeout: 5s
      retries: 5

  mc:
    image: minio/mc:latest
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: ["/bin/sh", "/init/create-buckets.sh"]
    volumes:
      - ./minio/create-buckets.sh:/init/create-buckets.sh:ro
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
      S3_BUCKET_LOGS: ${S3_BUCKET_LOGS}
      S3_BUCKET_RESULTS: ${S3_BUCKET_RESULTS}

  # ---------- Web App que genera logs ----------
  webapp:
    build:
      context: ./webapp
    environment:
      MINIO_ENDPOINT: ${MINIO_ENDPOINT}
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      AWS_REGION: ${AWS_REGION}
      S3_BUCKET_LOGS: ${S3_BUCKET_LOGS}
    ports:
      - "8080:8080"
    depends_on:
      minio:
        condition: service_healthy

  # ---------- Hadoop HDFS + YARN (BDE images) ----------
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    environment:
      CLUSTER_NAME: ${CLUSTER_NAME}
      CORE_CONF_fs_defaultFS: ${HDFS_NAMENODE_URI}
    ports:
      - "9870:9870"   # HDFS NameNode UI
    # volumes:
    #   - hadoop_namenode:/hadoop/dfs/name
    healthcheck:
      test: ["CMD", "bash", "-lc", "curl -f http://localhost:9870 || exit 1"]
      interval: 15s
      timeout: 5s
      retries: 10

  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    environment:
      CORE_CONF_fs_defaultFS: ${HDFS_NAMENODE_URI}
      SERVICE_PRECONDITION: "namenode:9870"
    # volumes:
    #   - hadoop_datanode:/hadoop/dfs/data
    scale: 3

  resourcemanager:
    image: bde2020/hadoop-resourcemanager:2.0.0-hadoop3.2.1-java8
    environment:
      CORE_CONF_fs_defaultFS: ${HDFS_NAMENODE_URI}
      SERVICE_PRECONDITION: "namenode:9870"
      YARN_CONF_yarn_resourcemanager_hostname: resourcemanager
      YARN_CONF_yarn_resourcemanager_address: resourcemanager:8032
      YARN_CONF_yarn_resourcemanager_scheduler__address: resourcemanager:8030
      YARN_CONF_yarn_resourcemanager_resource__tracker__address: resourcemanager:8031
      YARN_CONF_yarn_resourcemanager_webapp__address: resourcemanager:8088
      <<: *hadoop_env
    ports:
      - "8088:8088"  # YARN UI

  nodemanager:
    build:
      context: ./nodemanager
    image: paella/hadoop-nodemanager:2.0.0-hadoop3.2.1-java8-python
    environment:
      CORE_CONF_fs_defaultFS: ${HDFS_NAMENODE_URI}
      SERVICE_PRECONDITION: "namenode:9870 resourcemanager:8088"
      YARN_CONF_yarn_resourcemanager_hostname: resourcemanager
      YARN_CONF_yarn_resourcemanager_address: resourcemanager:8032
      YARN_CONF_yarn_resourcemanager_scheduler__address: resourcemanager:8030
      YARN_CONF_yarn_resourcemanager_resource__tracker__address: resourcemanager:8031
      <<: *hadoop_env
      YARN_CONF_yarn_nodemanager_env__whitelist: "JAVA_HOME,HADOOP_HOME,HADOOP_MAPRED_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_YARN_HOME,CLASSPATH,LD_LIBRARY_PATH,LANG,LANGUAGE,LC_ALL,PATH"
      YARN_CONF_yarn_nodemanager_resource_memory__mb: "2048"
      YARN_CONF_yarn_nodemanager_resource_cpu__vcores: "2"

  historyserver:
    image: bde2020/hadoop-historyserver:2.0.0-hadoop3.2.1-java8
    environment:
      CORE_CONF_fs_defaultFS: ${HDFS_NAMENODE_URI}
      SERVICE_PRECONDITION: "namenode:9870 resourcemanager:8088"
      <<: *hadoop_env
    ports:
      - "8188:8188"  # JobHistory UI

  # ---------- Cliente para enviar jobs ----------
  hadoop-client:
    build:
      context: ./hadoop-client
    hostname: hadoop-client
    extra_hosts:
      - "hadoop-client:127.0.0.1"
    environment:
      # HDFS/YARN
      HDFS_NAMENODE_URI: ${HDFS_NAMENODE_URI}
      YARN_RM_HOST: resourcemanager

      # MinIO / S3
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      AWS_REGION: ${AWS_REGION}
      MINIO_ENDPOINT: ${MINIO_ENDPOINT}
      S3_BUCKET_LOGS: ${S3_BUCKET_LOGS}
      S3_BUCKET_RESULTS: ${S3_BUCKET_RESULTS}
    depends_on:
      namenode:
        condition: service_healthy
      resourcemanager:
        condition: service_started
    volumes:
      - ./hadoop-client:/job
      - ./results:/results

volumes:
  minio_data:
